{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "936f8cb5",
   "metadata": {},
   "source": [
    "# Pretraitement des donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "31a6c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from skimage.transform import radon\n",
    "from skimage import io, color, filters\n",
    "import cv2\n",
    "\n",
    "def charger_images(dossier):\n",
    "    images = []\n",
    "    labels = []  \n",
    "\n",
    "    for nom_personne in os.listdir(dossier):\n",
    "        dossier_personne = os.path.join(dossier, nom_personne)\n",
    "        \n",
    "        if not os.path.isdir(dossier_personne):\n",
    "            continue\n",
    "\n",
    "        for nom_fichier in os.listdir(dossier_personne):\n",
    "            chemin_image = os.path.join(dossier_personne, nom_fichier)\n",
    "            if not nom_fichier.endswith(('.png', '.jpg', '.jpeg', '.PNG')):\n",
    "                continue\n",
    "\n",
    "            image = Image.open(chemin_image)\n",
    "            images.append(image)\n",
    "            labels.append(nom_personne)\n",
    "            \n",
    "    return images, labels\n",
    "\n",
    "# Chemin vers le dossier\n",
    "dossier_train = \"train_test\"\n",
    "\n",
    "# Charger les images et les étiquettes depuis le dossier train_test\n",
    "image_train_test, labels_train_test = charger_images(dossier_train)\n",
    "\n",
    "# Convertir les images en tableaux NumPy\n",
    "train_test_array = [np.array(image) for image in image_train_test]\n",
    "\n",
    "# Rendre les images array en des images carrees de meme taille\n",
    "train_test_array = [cv2.resize(image,(500,500)) for image in train_test_array]\n",
    "\n",
    "# Passer du niveaux en couleurs en niveaux de gris\n",
    "train_test_gray = [cv2.cvtColor(image,cv2.COLOR_BGR2GRAY) for image in train_test_array]\n",
    "\n",
    "# Filtrer le bruit des images avec un filtre median\n",
    "train_test_filtree = [cv2.medianBlur(image,5) for image in train_test_gray]\n",
    "\n",
    "# Binariser l'ensemble des images de training/test pour reduire la complexité de calcul des sinogrammes\n",
    "train_test_binary = [cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1] for image in train_test_filtree]\n",
    "\n",
    "# Déterminer les contours des signatures dans les images\n",
    "train_test_contours = [cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0] for image in train_test_binary]\n",
    "\n",
    "# Dessiner les contours des signatures sur les images\n",
    "p = len(train_test_contours)\n",
    "train_test_draw = [cv2.drawContours(train_test_binary[i], train_test_contours[i], -1, (255, 255, 255), 2) for i in range(p)]\n",
    "\n",
    "# Calculer la transformée de Radon des images de training\n",
    "    # Construire un ensemble de 180 angles de projections\n",
    "theta = np.linspace(0., 180., 180, endpoint = False)\n",
    "    # Construire les sinogrammes du training avec des projections le long d'une droite à chaque angle de projection donnée\n",
    "train_test_radon = [radon(image, theta = theta, circle = False) for image in train_test_draw]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc09f3b3",
   "metadata": {},
   "source": [
    "# Sauvegarde des sinogrammes de training/test en cas d'eventuelles nouvelles analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "c3e2cf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "Categories = []\n",
    "\n",
    "Labels = []\n",
    "\n",
    "for j in labels_train_test:\n",
    "    \n",
    "    if j not in Labels :\n",
    "        L = [i for i in labels_train_test if(i==j)]\n",
    "        Categories.append(L)\n",
    "        Labels.append(j)\n",
    "\n",
    "\n",
    "k = 0\n",
    "q = 0\n",
    "for L in Categories:\n",
    "    dossier = \"train_test_\" + L[0]\n",
    "    os.makedirs(dossier)\n",
    "    \n",
    "    k += len(L)\n",
    "    subset = train_test_radon[q:k]\n",
    "    \n",
    "    length = len(subset)\n",
    "    for s in range(length):\n",
    "        norm_matrix = (subset[s] - np.min(subset[s])) / (np.max(subset[s]) - np.min(subset[s])) * 255\n",
    "        image = Image.fromarray(norm_matrix.astype('uint8'))\n",
    "        im_format = 'sinog_' + str(s+1) + '.bmp'\n",
    "        dest = os.path.join(dossier,im_format)\n",
    "        image.save(dest)\n",
    "        \n",
    "    q = k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034af646",
   "metadata": {},
   "source": [
    "# Statistiques de l'ensemble training_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "b3b5a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Statistiques = []\n",
    "\n",
    "Id = [i for i in range(len(Labels))]\n",
    "\n",
    "for L in Categories:\n",
    "    Statistiques.append(len(L))\n",
    "\n",
    "Name = np.array(['Id','Classe','Occurence'])\n",
    "\n",
    "Resume_train_test = np.array(Labels)\n",
    "Resume_train_test = np.vstack((Resume_train_test,np.array(Statistiques)))\n",
    "Resume_train_test = np.vstack((np.array(Id),Resume_train_test))\n",
    "Resume_train_test = np.c_[Name.T,Resume_train_test]\n",
    "\n",
    "folder1 = \"Statistiques_train_test1.csv\"\n",
    "folder2 = \"Statistiques_train_test2.txt\"\n",
    "\n",
    "np.savetxt(folder1, Resume_train_test, fmt = '%s', delimiter = ',')\n",
    "np.savetxt(folder2, Resume_train_test, fmt = '%s', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c379ef6-7a8a-4194-a218-db794944451b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>118</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>121</td>\n",
       "      <td>122</td>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Classe</td>\n",
       "      <td>1</td>\n",
       "      <td>001_forg</td>\n",
       "      <td>2</td>\n",
       "      <td>002_forg</td>\n",
       "      <td>3</td>\n",
       "      <td>003_forg</td>\n",
       "      <td>4</td>\n",
       "      <td>004_forg</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>065_forg</td>\n",
       "      <td>66</td>\n",
       "      <td>066_forg</td>\n",
       "      <td>67</td>\n",
       "      <td>067_forg</td>\n",
       "      <td>68</td>\n",
       "      <td>068_forg</td>\n",
       "      <td>69</td>\n",
       "      <td>069_forg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Occurence</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1         2    3         4    5         6    7         8    9    \\\n",
       "0         Id    0         1    2         3    4         5    6         7    8   \n",
       "1     Classe    1  001_forg    2  002_forg    3  003_forg    4  004_forg    6   \n",
       "2  Occurence   24         8   24        12   24        12   24        11   24   \n",
       "\n",
       "   ...  119       120  121       122  123       124  125       126  127  \\\n",
       "0  ...  118       119  120       121  122       123  124       125  126   \n",
       "1  ...   65  065_forg   66  066_forg   67  067_forg   68  068_forg   69   \n",
       "2  ...   12         8   12        16   12         8   12         8   12   \n",
       "\n",
       "        128  \n",
       "0       127  \n",
       "1  069_forg  \n",
       "2        12  \n",
       "\n",
       "[3 rows x 129 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Stats = pd.read_table(\"Statistiques_train_test2.txt\", header = None)\n",
    "Stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f188a28f",
   "metadata": {},
   "source": [
    "# Utilisation d'un réseau de neurones CNN pour la classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231e52cc",
   "metadata": {},
   "source": [
    "    # Augmentation de nos données pour une bonne généralisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07f12c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pc\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest'\n",
    ")\n",
    "\n",
    "def data_augmentate(dossier):\n",
    "    \n",
    "    labels_train_test = []\n",
    "    augmented_data = []\n",
    "    images = []\n",
    "    \n",
    "    classe = 1\n",
    "    \n",
    "    for nom_personne in os.listdir(dossier):\n",
    "        dossier_personne = os.path.join(dossier, nom_personne)\n",
    "        \n",
    "        if not os.path.isdir(dossier_personne):\n",
    "            continue\n",
    "\n",
    "        for nom_fichier in os.listdir(dossier_personne):\n",
    "            chemin_image = os.path.join(dossier_personne, nom_fichier)\n",
    "            if not nom_fichier.endswith(('.bmp')):\n",
    "                continue\n",
    "\n",
    "            image = Image.open(chemin_image)\n",
    "            images.append(image)\n",
    "        \n",
    "        images = [np.array(image) for image in images]\n",
    "        images = [ cv2.resize(image, (100,100)) for image in images]\n",
    "        images = [list(image.flatten()) for image in images]\n",
    "        images = np.array(images)\n",
    "        \n",
    "        images_reshaped = images.reshape(-1, 100, 100, 1)\n",
    "\n",
    "        for i in range(images_reshaped.shape[0]):\n",
    "            # Obtenir une image\n",
    "            img = images_reshaped[i]\n",
    "\n",
    "            augmented_data.append(img.flatten().tolist())\n",
    "            labels_train_test.append(classe)\n",
    "            \n",
    "            # Ajouter une dimension supplémentaire pour le lot\n",
    "            img = np.expand_dims(img, axis = 0)\n",
    "            \n",
    "            # Générer 10 images augmentées de l'image\n",
    "            for k in range(10):\n",
    "                augmented_image = datagen.flow(img, batch_size = 1).next()[0]\n",
    "                # Ajouter l'image augmentée au tableau\n",
    "                augmented_data.append(augmented_image.flatten().tolist())\n",
    "                \n",
    "                labels_train_test.append(classe)\n",
    "        \n",
    "        images = [] \n",
    "        classe += 1\n",
    "        \n",
    "    # Transformer la liste en un tableau NumPy\n",
    "    augmented_data = np.array(augmented_data)\n",
    "    \n",
    "    labels_train_test = np.array(labels_train_test)\n",
    "    \n",
    "    return augmented_data, labels_train_test\n",
    "\n",
    "data, labels = data_augmentate(\"sinogram_train_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e854691e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18139, 10000)\n",
      "(18139,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a791ae28-fec2-440c-bf0d-ddae4c966493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pc\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def load_sinogramme(dossier):\n",
    "    \n",
    "    labels_train_test = []\n",
    "    data = []\n",
    "    images = []\n",
    "    \n",
    "    classe = 1\n",
    "    \n",
    "    for nom_personne in os.listdir(dossier):\n",
    "        dossier_personne = os.path.join(dossier, nom_personne)\n",
    "        \n",
    "        if not os.path.isdir(dossier_personne):\n",
    "            continue\n",
    "\n",
    "        for nom_fichier in os.listdir(dossier_personne):\n",
    "            chemin_image = os.path.join(dossier_personne, nom_fichier)\n",
    "            if not nom_fichier.endswith(('.bmp')):\n",
    "                continue\n",
    "\n",
    "            image = Image.open(chemin_image)\n",
    "            images.append(image)\n",
    "        \n",
    "        images = [np.array(image) for image in images]\n",
    "        images = [ cv2.resize(image, (100,100)) for image in images]\n",
    "\n",
    "        for image in images:\n",
    "            data.append(list(image.flatten()))\n",
    "            labels_train_test.append(classe)\n",
    "        \n",
    "        \n",
    "        images = [] \n",
    "        classe += 1\n",
    "        \n",
    "    # Transformer la liste en un tableau NumPy\n",
    "    data = np.array(data)\n",
    "    \n",
    "    labels_train_test = np.array(labels_train_test)\n",
    "    \n",
    "    return data, labels_train_test\n",
    "\n",
    "data, labels = load_sinogramme(\"sinogram_train_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a92d8827-0651-4e7b-9dbe-23051a23dd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1649, 10000)\n",
      "(1649,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d7ee37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "13/13 [==============================] - 16s 1s/step - loss: 21.0988 - accuracy: 0.0054 - val_loss: 4.8516 - val_accuracy: 0.0037\n",
      "Epoch 2/250\n",
      "13/13 [==============================] - 9s 708ms/step - loss: 4.8774 - accuracy: 0.0082 - val_loss: 4.8528 - val_accuracy: 0.0073\n",
      "Epoch 3/250\n",
      "13/13 [==============================] - 9s 720ms/step - loss: 4.8510 - accuracy: 0.0118 - val_loss: 4.8534 - val_accuracy: 0.0055\n",
      "Epoch 4/250\n",
      "13/13 [==============================] - 10s 767ms/step - loss: 4.8477 - accuracy: 0.0172 - val_loss: 4.8524 - val_accuracy: 0.0055\n",
      "Epoch 5/250\n",
      "13/13 [==============================] - 9s 699ms/step - loss: 4.8431 - accuracy: 0.0163 - val_loss: 4.8516 - val_accuracy: 0.0055\n",
      "Epoch 6/250\n",
      "13/13 [==============================] - 9s 699ms/step - loss: 4.8408 - accuracy: 0.0163 - val_loss: 4.8521 - val_accuracy: 0.0055\n",
      "Epoch 7/250\n",
      "13/13 [==============================] - 9s 658ms/step - loss: 4.8370 - accuracy: 0.0190 - val_loss: 4.8520 - val_accuracy: 0.0037\n",
      "Epoch 8/250\n",
      "13/13 [==============================] - 8s 650ms/step - loss: 4.8381 - accuracy: 0.0190 - val_loss: 4.8511 - val_accuracy: 0.0092\n",
      "Epoch 9/250\n",
      "13/13 [==============================] - 8s 589ms/step - loss: 4.8272 - accuracy: 0.0181 - val_loss: 4.8531 - val_accuracy: 0.0055\n",
      "Epoch 10/250\n",
      "13/13 [==============================] - 9s 694ms/step - loss: 4.8299 - accuracy: 0.0154 - val_loss: 4.8562 - val_accuracy: 0.0055\n",
      "Epoch 11/250\n",
      "13/13 [==============================] - 11s 822ms/step - loss: 4.8230 - accuracy: 0.0181 - val_loss: 4.8619 - val_accuracy: 0.0055\n",
      "Epoch 12/250\n",
      "13/13 [==============================] - 11s 813ms/step - loss: 4.8240 - accuracy: 0.0199 - val_loss: 4.8572 - val_accuracy: 0.0147\n",
      "Epoch 13/250\n",
      "13/13 [==============================] - 9s 721ms/step - loss: 4.8226 - accuracy: 0.0154 - val_loss: 4.8580 - val_accuracy: 0.0055\n",
      "Epoch 14/250\n",
      "13/13 [==============================] - 9s 678ms/step - loss: 4.8253 - accuracy: 0.0163 - val_loss: 4.8574 - val_accuracy: 0.0165\n",
      "Epoch 15/250\n",
      "13/13 [==============================] - 9s 668ms/step - loss: 4.8270 - accuracy: 0.0172 - val_loss: 4.8584 - val_accuracy: 0.0147\n",
      "Epoch 16/250\n",
      "13/13 [==============================] - 6s 446ms/step - loss: 4.8144 - accuracy: 0.0154 - val_loss: 4.8617 - val_accuracy: 0.0055\n",
      "Epoch 17/250\n",
      "13/13 [==============================] - 6s 466ms/step - loss: 4.8196 - accuracy: 0.0181 - val_loss: 4.8638 - val_accuracy: 0.0165\n",
      "Epoch 18/250\n",
      "13/13 [==============================] - 6s 471ms/step - loss: 4.8143 - accuracy: 0.0136 - val_loss: 4.8656 - val_accuracy: 0.0055\n",
      "Epoch 19/250\n",
      "13/13 [==============================] - 6s 461ms/step - loss: 4.8171 - accuracy: 0.0263 - val_loss: 4.8601 - val_accuracy: 0.0055\n",
      "Epoch 20/250\n",
      "13/13 [==============================] - 6s 464ms/step - loss: 4.8167 - accuracy: 0.0145 - val_loss: 4.8606 - val_accuracy: 0.0055\n",
      "Epoch 21/250\n",
      "13/13 [==============================] - 7s 533ms/step - loss: 4.8153 - accuracy: 0.0208 - val_loss: 4.8644 - val_accuracy: 0.0073\n",
      "Epoch 22/250\n",
      "13/13 [==============================] - 6s 448ms/step - loss: 4.8061 - accuracy: 0.0154 - val_loss: 4.8666 - val_accuracy: 0.0055\n",
      "Epoch 23/250\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 4.8039 - accuracy: 0.0208 - val_loss: 4.8730 - val_accuracy: 0.0092\n",
      "Epoch 24/250\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 4.8098 - accuracy: 0.0154 - val_loss: 4.8725 - val_accuracy: 0.0128\n",
      "Epoch 25/250\n",
      "13/13 [==============================] - 6s 446ms/step - loss: 4.8041 - accuracy: 0.0226 - val_loss: 4.8740 - val_accuracy: 0.0147\n",
      "Epoch 26/250\n",
      "13/13 [==============================] - 9s 704ms/step - loss: 4.8096 - accuracy: 0.0181 - val_loss: 4.8624 - val_accuracy: 0.0110\n",
      "Epoch 27/250\n",
      "13/13 [==============================] - 7s 571ms/step - loss: 4.8100 - accuracy: 0.0226 - val_loss: 4.8625 - val_accuracy: 0.0110\n",
      "Epoch 28/250\n",
      "13/13 [==============================] - 7s 556ms/step - loss: 4.8003 - accuracy: 0.0208 - val_loss: 4.8718 - val_accuracy: 0.0073\n",
      "Epoch 29/250\n",
      "13/13 [==============================] - 6s 469ms/step - loss: 4.8068 - accuracy: 0.0199 - val_loss: 4.8705 - val_accuracy: 0.0128\n",
      "Epoch 30/250\n",
      "13/13 [==============================] - 6s 495ms/step - loss: 4.8010 - accuracy: 0.0163 - val_loss: 4.8665 - val_accuracy: 0.0147\n",
      "Epoch 31/250\n",
      "13/13 [==============================] - 6s 477ms/step - loss: 4.8035 - accuracy: 0.0199 - val_loss: 4.8687 - val_accuracy: 0.0147\n",
      "Epoch 32/250\n",
      "13/13 [==============================] - 6s 493ms/step - loss: 4.8061 - accuracy: 0.0254 - val_loss: 4.8670 - val_accuracy: 0.0147\n",
      "Epoch 33/250\n",
      "13/13 [==============================] - 6s 455ms/step - loss: 4.8015 - accuracy: 0.0190 - val_loss: 4.8652 - val_accuracy: 0.0110\n",
      "Epoch 34/250\n",
      "13/13 [==============================] - 6s 460ms/step - loss: 4.8017 - accuracy: 0.0217 - val_loss: 4.8679 - val_accuracy: 0.0110\n",
      "Epoch 35/250\n",
      "13/13 [==============================] - 6s 434ms/step - loss: 4.7954 - accuracy: 0.0254 - val_loss: 4.8710 - val_accuracy: 0.0128\n",
      "Epoch 36/250\n",
      "13/13 [==============================] - 6s 463ms/step - loss: 4.7945 - accuracy: 0.0245 - val_loss: 4.8679 - val_accuracy: 0.0110\n",
      "Epoch 37/250\n",
      "13/13 [==============================] - 6s 490ms/step - loss: 4.7925 - accuracy: 0.0181 - val_loss: 4.8712 - val_accuracy: 0.0092\n",
      "Epoch 38/250\n",
      "13/13 [==============================] - 6s 503ms/step - loss: 4.7863 - accuracy: 0.0245 - val_loss: 4.8688 - val_accuracy: 0.0128\n",
      "Epoch 39/250\n",
      "13/13 [==============================] - 6s 445ms/step - loss: 4.7991 - accuracy: 0.0208 - val_loss: 4.8624 - val_accuracy: 0.0073\n",
      "Epoch 40/250\n",
      "13/13 [==============================] - 6s 453ms/step - loss: 4.7875 - accuracy: 0.0290 - val_loss: 4.8646 - val_accuracy: 0.0128\n",
      "Epoch 41/250\n",
      "13/13 [==============================] - 6s 431ms/step - loss: 4.7799 - accuracy: 0.0254 - val_loss: 4.8620 - val_accuracy: 0.0257\n",
      "Epoch 42/250\n",
      "13/13 [==============================] - 6s 450ms/step - loss: 4.7857 - accuracy: 0.0236 - val_loss: 4.8602 - val_accuracy: 0.0220\n",
      "Epoch 43/250\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 4.7923 - accuracy: 0.0172 - val_loss: 4.8559 - val_accuracy: 0.0220\n",
      "Epoch 44/250\n",
      "13/13 [==============================] - 6s 489ms/step - loss: 4.7985 - accuracy: 0.0163 - val_loss: 4.8523 - val_accuracy: 0.0073\n",
      "Epoch 45/250\n",
      "13/13 [==============================] - 6s 456ms/step - loss: 4.7715 - accuracy: 0.0181 - val_loss: 4.8506 - val_accuracy: 0.0073\n",
      "Epoch 46/250\n",
      "13/13 [==============================] - 6s 488ms/step - loss: 4.7742 - accuracy: 0.0236 - val_loss: 4.8430 - val_accuracy: 0.0165\n",
      "Epoch 47/250\n",
      "13/13 [==============================] - 6s 485ms/step - loss: 4.7783 - accuracy: 0.0236 - val_loss: 4.8437 - val_accuracy: 0.0128\n",
      "Epoch 48/250\n",
      "13/13 [==============================] - 6s 458ms/step - loss: 4.7784 - accuracy: 0.0245 - val_loss: 4.8504 - val_accuracy: 0.0073\n",
      "Epoch 49/250\n",
      "13/13 [==============================] - 6s 464ms/step - loss: 4.7618 - accuracy: 0.0217 - val_loss: 4.8348 - val_accuracy: 0.0147\n",
      "Epoch 50/250\n",
      "13/13 [==============================] - 6s 504ms/step - loss: 4.7534 - accuracy: 0.0290 - val_loss: 4.8366 - val_accuracy: 0.0128\n",
      "Epoch 51/250\n",
      "13/13 [==============================] - 6s 459ms/step - loss: 4.7664 - accuracy: 0.0245 - val_loss: 4.8263 - val_accuracy: 0.0147\n",
      "Epoch 52/250\n",
      "13/13 [==============================] - 6s 442ms/step - loss: 4.7631 - accuracy: 0.0281 - val_loss: 4.8471 - val_accuracy: 0.0092\n",
      "Epoch 53/250\n",
      "13/13 [==============================] - 6s 441ms/step - loss: 4.7613 - accuracy: 0.0344 - val_loss: 4.8409 - val_accuracy: 0.0073\n",
      "Epoch 54/250\n",
      "13/13 [==============================] - 5s 423ms/step - loss: 4.7515 - accuracy: 0.0326 - val_loss: 4.8114 - val_accuracy: 0.0147\n",
      "Epoch 55/250\n",
      "13/13 [==============================] - 6s 427ms/step - loss: 4.7564 - accuracy: 0.0245 - val_loss: 4.8179 - val_accuracy: 0.0147\n",
      "Epoch 56/250\n",
      "13/13 [==============================] - 6s 450ms/step - loss: 4.7479 - accuracy: 0.0290 - val_loss: 4.8473 - val_accuracy: 0.0073\n",
      "Epoch 57/250\n",
      "13/13 [==============================] - 5s 418ms/step - loss: 4.7763 - accuracy: 0.0290 - val_loss: 4.8417 - val_accuracy: 0.0147\n",
      "Epoch 58/250\n",
      "13/13 [==============================] - 7s 516ms/step - loss: 4.7669 - accuracy: 0.0245 - val_loss: 4.8241 - val_accuracy: 0.0165\n",
      "Epoch 59/250\n",
      "13/13 [==============================] - 6s 451ms/step - loss: 4.7552 - accuracy: 0.0317 - val_loss: 4.8147 - val_accuracy: 0.0147\n",
      "Epoch 60/250\n",
      "13/13 [==============================] - 6s 456ms/step - loss: 4.7080 - accuracy: 0.0380 - val_loss: 4.7979 - val_accuracy: 0.0165\n",
      "Epoch 61/250\n",
      "13/13 [==============================] - 6s 426ms/step - loss: 4.7037 - accuracy: 0.0335 - val_loss: 4.7694 - val_accuracy: 0.0257\n",
      "Epoch 62/250\n",
      "13/13 [==============================] - 6s 479ms/step - loss: 4.7222 - accuracy: 0.0281 - val_loss: 4.7877 - val_accuracy: 0.0165\n",
      "Epoch 63/250\n",
      "13/13 [==============================] - 6s 440ms/step - loss: 4.7286 - accuracy: 0.0272 - val_loss: 4.8124 - val_accuracy: 0.0147\n",
      "Epoch 64/250\n",
      "13/13 [==============================] - 6s 438ms/step - loss: 4.7312 - accuracy: 0.0272 - val_loss: 4.7863 - val_accuracy: 0.0202\n",
      "Epoch 65/250\n",
      "13/13 [==============================] - 6s 441ms/step - loss: 4.7075 - accuracy: 0.0362 - val_loss: 4.7555 - val_accuracy: 0.0202\n",
      "Epoch 66/250\n",
      "13/13 [==============================] - 5s 410ms/step - loss: 4.7050 - accuracy: 0.0380 - val_loss: 4.7668 - val_accuracy: 0.0183\n",
      "Epoch 67/250\n",
      "13/13 [==============================] - 6s 436ms/step - loss: 4.6783 - accuracy: 0.0371 - val_loss: 4.7383 - val_accuracy: 0.0239\n",
      "Epoch 68/250\n",
      "13/13 [==============================] - 8s 628ms/step - loss: 4.6781 - accuracy: 0.0362 - val_loss: 4.7350 - val_accuracy: 0.0257\n",
      "Epoch 69/250\n",
      "13/13 [==============================] - 7s 540ms/step - loss: 4.6331 - accuracy: 0.0444 - val_loss: 4.7389 - val_accuracy: 0.0239\n",
      "Epoch 70/250\n",
      "13/13 [==============================] - 7s 515ms/step - loss: 4.6457 - accuracy: 0.0444 - val_loss: 4.7396 - val_accuracy: 0.0220\n",
      "Epoch 71/250\n",
      "13/13 [==============================] - 6s 494ms/step - loss: 4.6250 - accuracy: 0.0471 - val_loss: 4.6632 - val_accuracy: 0.0440\n",
      "Epoch 72/250\n",
      "13/13 [==============================] - 6s 442ms/step - loss: 4.6096 - accuracy: 0.0453 - val_loss: 4.6655 - val_accuracy: 0.0440\n",
      "Epoch 73/250\n",
      "13/13 [==============================] - 7s 507ms/step - loss: 4.5406 - accuracy: 0.0580 - val_loss: 4.6488 - val_accuracy: 0.0532\n",
      "Epoch 74/250\n",
      "13/13 [==============================] - 6s 492ms/step - loss: 4.6153 - accuracy: 0.0507 - val_loss: 4.7276 - val_accuracy: 0.0440\n",
      "Epoch 75/250\n",
      "13/13 [==============================] - 7s 502ms/step - loss: 4.6309 - accuracy: 0.0417 - val_loss: 4.6740 - val_accuracy: 0.0440\n",
      "Epoch 76/250\n",
      "13/13 [==============================] - 6s 504ms/step - loss: 4.5598 - accuracy: 0.0498 - val_loss: 4.6231 - val_accuracy: 0.0440\n",
      "Epoch 77/250\n",
      "13/13 [==============================] - 7s 521ms/step - loss: 4.5658 - accuracy: 0.0516 - val_loss: 4.6075 - val_accuracy: 0.0422\n",
      "Epoch 78/250\n",
      "13/13 [==============================] - 9s 693ms/step - loss: 4.5256 - accuracy: 0.0571 - val_loss: 4.5736 - val_accuracy: 0.0459\n",
      "Epoch 79/250\n",
      "13/13 [==============================] - 9s 680ms/step - loss: 4.4562 - accuracy: 0.0543 - val_loss: 4.5838 - val_accuracy: 0.0587\n",
      "Epoch 80/250\n",
      "13/13 [==============================] - 8s 604ms/step - loss: 4.5010 - accuracy: 0.0580 - val_loss: 4.5928 - val_accuracy: 0.0367\n",
      "Epoch 81/250\n",
      "13/13 [==============================] - 10s 720ms/step - loss: 4.4724 - accuracy: 0.0625 - val_loss: 4.6306 - val_accuracy: 0.0404\n",
      "Epoch 82/250\n",
      "13/13 [==============================] - 9s 720ms/step - loss: 4.4347 - accuracy: 0.0707 - val_loss: 4.4855 - val_accuracy: 0.0752\n",
      "Epoch 83/250\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 4.3391 - accuracy: 0.0716 - val_loss: 4.5638 - val_accuracy: 0.0330\n",
      "Epoch 84/250\n",
      "13/13 [==============================] - 9s 661ms/step - loss: 4.4114 - accuracy: 0.0580 - val_loss: 4.3922 - val_accuracy: 0.0826\n",
      "Epoch 85/250\n",
      "13/13 [==============================] - 10s 777ms/step - loss: 4.2937 - accuracy: 0.0770 - val_loss: 4.2577 - val_accuracy: 0.1156\n",
      "Epoch 86/250\n",
      "13/13 [==============================] - 8s 641ms/step - loss: 4.2745 - accuracy: 0.0870 - val_loss: 4.5432 - val_accuracy: 0.0404\n",
      "Epoch 87/250\n",
      "13/13 [==============================] - 6s 444ms/step - loss: 4.2917 - accuracy: 0.0942 - val_loss: 4.4603 - val_accuracy: 0.0587\n",
      "Epoch 88/250\n",
      "13/13 [==============================] - 6s 448ms/step - loss: 4.1863 - accuracy: 0.0924 - val_loss: 4.1663 - val_accuracy: 0.1413\n",
      "Epoch 89/250\n",
      "13/13 [==============================] - 6s 436ms/step - loss: 4.1099 - accuracy: 0.1286 - val_loss: 4.0488 - val_accuracy: 0.1798\n",
      "Epoch 90/250\n",
      "13/13 [==============================] - 5s 396ms/step - loss: 4.1825 - accuracy: 0.0924 - val_loss: 3.9069 - val_accuracy: 0.2183\n",
      "Epoch 91/250\n",
      "13/13 [==============================] - 6s 459ms/step - loss: 4.0752 - accuracy: 0.1187 - val_loss: 3.9286 - val_accuracy: 0.2165\n",
      "Epoch 92/250\n",
      "13/13 [==============================] - 6s 469ms/step - loss: 3.9814 - accuracy: 0.1286 - val_loss: 4.2273 - val_accuracy: 0.1431\n",
      "Epoch 93/250\n",
      "13/13 [==============================] - 5s 406ms/step - loss: 3.9977 - accuracy: 0.1268 - val_loss: 3.6784 - val_accuracy: 0.2624\n",
      "Epoch 94/250\n",
      "13/13 [==============================] - 6s 460ms/step - loss: 3.9022 - accuracy: 0.1386 - val_loss: 3.6098 - val_accuracy: 0.2606\n",
      "Epoch 95/250\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 3.6957 - accuracy: 0.1739 - val_loss: 4.1633 - val_accuracy: 0.1174\n",
      "Epoch 96/250\n",
      "13/13 [==============================] - 6s 457ms/step - loss: 3.9283 - accuracy: 0.1313 - val_loss: 3.7136 - val_accuracy: 0.2606\n",
      "Epoch 97/250\n",
      "13/13 [==============================] - 6s 467ms/step - loss: 3.6856 - accuracy: 0.1685 - val_loss: 3.7643 - val_accuracy: 0.2239\n",
      "Epoch 98/250\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 3.6112 - accuracy: 0.1848 - val_loss: 3.4437 - val_accuracy: 0.2789\n",
      "Epoch 99/250\n",
      "13/13 [==============================] - 6s 455ms/step - loss: 3.4648 - accuracy: 0.2147 - val_loss: 3.1401 - val_accuracy: 0.2954\n",
      "Epoch 100/250\n",
      "13/13 [==============================] - 6s 492ms/step - loss: 3.4286 - accuracy: 0.2020 - val_loss: 3.2773 - val_accuracy: 0.3119\n",
      "Epoch 101/250\n",
      "13/13 [==============================] - 5s 426ms/step - loss: 3.5650 - accuracy: 0.1812 - val_loss: 3.5323 - val_accuracy: 0.2422\n",
      "Epoch 102/250\n",
      "13/13 [==============================] - 5s 414ms/step - loss: 3.4204 - accuracy: 0.2120 - val_loss: 3.0108 - val_accuracy: 0.3431\n",
      "Epoch 103/250\n",
      "13/13 [==============================] - 5s 419ms/step - loss: 3.3110 - accuracy: 0.2428 - val_loss: 3.0210 - val_accuracy: 0.3413\n",
      "Epoch 104/250\n",
      "13/13 [==============================] - 6s 441ms/step - loss: 3.1944 - accuracy: 0.2636 - val_loss: 2.8807 - val_accuracy: 0.3670\n",
      "Epoch 105/250\n",
      "13/13 [==============================] - 6s 465ms/step - loss: 3.2219 - accuracy: 0.2409 - val_loss: 2.8816 - val_accuracy: 0.3670\n",
      "Epoch 106/250\n",
      "13/13 [==============================] - 5s 420ms/step - loss: 3.0862 - accuracy: 0.2645 - val_loss: 2.6585 - val_accuracy: 0.3853\n",
      "Epoch 107/250\n",
      "13/13 [==============================] - 6s 451ms/step - loss: 3.0345 - accuracy: 0.2582 - val_loss: 2.5265 - val_accuracy: 0.3908\n",
      "Epoch 108/250\n",
      "13/13 [==============================] - 6s 470ms/step - loss: 3.0816 - accuracy: 0.2509 - val_loss: 2.9903 - val_accuracy: 0.3615\n",
      "Epoch 109/250\n",
      "13/13 [==============================] - 6s 437ms/step - loss: 3.0790 - accuracy: 0.2745 - val_loss: 2.6689 - val_accuracy: 0.4385\n",
      "Epoch 110/250\n",
      "13/13 [==============================] - 6s 468ms/step - loss: 2.9736 - accuracy: 0.2754 - val_loss: 2.8710 - val_accuracy: 0.3798\n",
      "Epoch 111/250\n",
      "13/13 [==============================] - 6s 465ms/step - loss: 2.8935 - accuracy: 0.3216 - val_loss: 2.3808 - val_accuracy: 0.4294\n",
      "Epoch 112/250\n",
      "13/13 [==============================] - 6s 487ms/step - loss: 2.8938 - accuracy: 0.3043 - val_loss: 2.4637 - val_accuracy: 0.4367\n",
      "Epoch 113/250\n",
      "13/13 [==============================] - 8s 628ms/step - loss: 2.7961 - accuracy: 0.3125 - val_loss: 2.3855 - val_accuracy: 0.4514\n",
      "Epoch 114/250\n",
      "13/13 [==============================] - 6s 488ms/step - loss: 2.6718 - accuracy: 0.3424 - val_loss: 2.2664 - val_accuracy: 0.4807\n",
      "Epoch 115/250\n",
      "13/13 [==============================] - 6s 481ms/step - loss: 2.6873 - accuracy: 0.3288 - val_loss: 2.4022 - val_accuracy: 0.4422\n",
      "Epoch 116/250\n",
      "13/13 [==============================] - 6s 480ms/step - loss: 2.5571 - accuracy: 0.3614 - val_loss: 2.0599 - val_accuracy: 0.5028\n",
      "Epoch 117/250\n",
      "13/13 [==============================] - 6s 439ms/step - loss: 2.3385 - accuracy: 0.3895 - val_loss: 2.3012 - val_accuracy: 0.4569\n",
      "Epoch 118/250\n",
      "13/13 [==============================] - 6s 458ms/step - loss: 2.4093 - accuracy: 0.3859 - val_loss: 2.0571 - val_accuracy: 0.5211\n",
      "Epoch 119/250\n",
      "13/13 [==============================] - 6s 460ms/step - loss: 2.4536 - accuracy: 0.3750 - val_loss: 1.9877 - val_accuracy: 0.4972\n",
      "Epoch 120/250\n",
      "13/13 [==============================] - 6s 466ms/step - loss: 2.4525 - accuracy: 0.3596 - val_loss: 1.9062 - val_accuracy: 0.5523\n",
      "Epoch 121/250\n",
      "13/13 [==============================] - 6s 440ms/step - loss: 2.3486 - accuracy: 0.3822 - val_loss: 1.9458 - val_accuracy: 0.5119\n",
      "Epoch 122/250\n",
      "13/13 [==============================] - 7s 508ms/step - loss: 2.2232 - accuracy: 0.4357 - val_loss: 1.8988 - val_accuracy: 0.5101\n",
      "Epoch 123/250\n",
      "13/13 [==============================] - 6s 455ms/step - loss: 2.1422 - accuracy: 0.4293 - val_loss: 1.9950 - val_accuracy: 0.5394\n",
      "Epoch 124/250\n",
      "13/13 [==============================] - 6s 497ms/step - loss: 2.0621 - accuracy: 0.4710 - val_loss: 1.8715 - val_accuracy: 0.5413\n",
      "Epoch 125/250\n",
      "13/13 [==============================] - 6s 451ms/step - loss: 2.1125 - accuracy: 0.4475 - val_loss: 1.8302 - val_accuracy: 0.5413\n",
      "Epoch 126/250\n",
      "13/13 [==============================] - 6s 465ms/step - loss: 1.9789 - accuracy: 0.4674 - val_loss: 1.7879 - val_accuracy: 0.5578\n",
      "Epoch 127/250\n",
      "13/13 [==============================] - 6s 455ms/step - loss: 2.0017 - accuracy: 0.4538 - val_loss: 1.8451 - val_accuracy: 0.5431\n",
      "Epoch 128/250\n",
      "13/13 [==============================] - 6s 422ms/step - loss: 1.9972 - accuracy: 0.4592 - val_loss: 1.9589 - val_accuracy: 0.5358\n",
      "Epoch 129/250\n",
      "13/13 [==============================] - 6s 464ms/step - loss: 2.0003 - accuracy: 0.4737 - val_loss: 1.7111 - val_accuracy: 0.5890\n",
      "Epoch 130/250\n",
      "13/13 [==============================] - 6s 463ms/step - loss: 1.8916 - accuracy: 0.4882 - val_loss: 1.7184 - val_accuracy: 0.5780\n",
      "Epoch 131/250\n",
      "13/13 [==============================] - 6s 460ms/step - loss: 1.8632 - accuracy: 0.5063 - val_loss: 1.7064 - val_accuracy: 0.5651\n",
      "Epoch 132/250\n",
      "13/13 [==============================] - 6s 470ms/step - loss: 1.7925 - accuracy: 0.5009 - val_loss: 1.7116 - val_accuracy: 0.5670\n",
      "Epoch 133/250\n",
      "13/13 [==============================] - 6s 483ms/step - loss: 1.6890 - accuracy: 0.5435 - val_loss: 1.7770 - val_accuracy: 0.5578\n",
      "Epoch 134/250\n",
      "13/13 [==============================] - 6s 478ms/step - loss: 1.7727 - accuracy: 0.5217 - val_loss: 1.6315 - val_accuracy: 0.5927\n",
      "Epoch 135/250\n",
      "13/13 [==============================] - 7s 557ms/step - loss: 1.8059 - accuracy: 0.5281 - val_loss: 1.6735 - val_accuracy: 0.6000\n",
      "Epoch 136/250\n",
      "13/13 [==============================] - 7s 510ms/step - loss: 1.8367 - accuracy: 0.4991 - val_loss: 1.6572 - val_accuracy: 0.5963\n",
      "Epoch 137/250\n",
      "13/13 [==============================] - 6s 451ms/step - loss: 1.6716 - accuracy: 0.5335 - val_loss: 1.5796 - val_accuracy: 0.6018\n",
      "Epoch 138/250\n",
      "13/13 [==============================] - 6s 427ms/step - loss: 1.7581 - accuracy: 0.5127 - val_loss: 1.6283 - val_accuracy: 0.5890\n",
      "Epoch 139/250\n",
      "13/13 [==============================] - 6s 430ms/step - loss: 1.7559 - accuracy: 0.5163 - val_loss: 1.5920 - val_accuracy: 0.6147\n",
      "Epoch 140/250\n",
      "13/13 [==============================] - 6s 427ms/step - loss: 1.5951 - accuracy: 0.5543 - val_loss: 1.6097 - val_accuracy: 0.6110\n",
      "Epoch 141/250\n",
      "13/13 [==============================] - 6s 445ms/step - loss: 1.6766 - accuracy: 0.5589 - val_loss: 1.6059 - val_accuracy: 0.6000\n",
      "Epoch 142/250\n",
      "13/13 [==============================] - 5s 412ms/step - loss: 1.7332 - accuracy: 0.5371 - val_loss: 1.6899 - val_accuracy: 0.5798\n",
      "Epoch 143/250\n",
      "13/13 [==============================] - 5s 402ms/step - loss: 1.6217 - accuracy: 0.5498 - val_loss: 1.5799 - val_accuracy: 0.6037\n",
      "Epoch 144/250\n",
      "13/13 [==============================] - 5s 399ms/step - loss: 1.5225 - accuracy: 0.5797 - val_loss: 1.7042 - val_accuracy: 0.5853\n",
      "Epoch 145/250\n",
      "13/13 [==============================] - 5s 410ms/step - loss: 1.6233 - accuracy: 0.5435 - val_loss: 1.5085 - val_accuracy: 0.6147\n",
      "Epoch 146/250\n",
      "13/13 [==============================] - 5s 419ms/step - loss: 1.4788 - accuracy: 0.5743 - val_loss: 1.4963 - val_accuracy: 0.6275\n",
      "Epoch 147/250\n",
      "13/13 [==============================] - 5s 405ms/step - loss: 1.5712 - accuracy: 0.5761 - val_loss: 1.5642 - val_accuracy: 0.6092\n",
      "Epoch 148/250\n",
      "13/13 [==============================] - 5s 416ms/step - loss: 1.4956 - accuracy: 0.5897 - val_loss: 1.5615 - val_accuracy: 0.6128\n",
      "Epoch 149/250\n",
      "13/13 [==============================] - 5s 404ms/step - loss: 1.4735 - accuracy: 0.5933 - val_loss: 1.5305 - val_accuracy: 0.6110\n",
      "Epoch 150/250\n",
      "13/13 [==============================] - 5s 387ms/step - loss: 1.3425 - accuracy: 0.6304 - val_loss: 1.4861 - val_accuracy: 0.6330\n",
      "Epoch 151/250\n",
      "13/13 [==============================] - 5s 400ms/step - loss: 1.3552 - accuracy: 0.6159 - val_loss: 1.5254 - val_accuracy: 0.6183\n",
      "Epoch 152/250\n",
      "13/13 [==============================] - 5s 421ms/step - loss: 1.3989 - accuracy: 0.6150 - val_loss: 1.5569 - val_accuracy: 0.6110\n",
      "Epoch 153/250\n",
      "13/13 [==============================] - 5s 399ms/step - loss: 1.2746 - accuracy: 0.6386 - val_loss: 1.5794 - val_accuracy: 0.6037\n",
      "Epoch 154/250\n",
      "13/13 [==============================] - 5s 396ms/step - loss: 1.3748 - accuracy: 0.6159 - val_loss: 1.6228 - val_accuracy: 0.5927\n",
      "Epoch 155/250\n",
      "13/13 [==============================] - 6s 428ms/step - loss: 1.4795 - accuracy: 0.5833 - val_loss: 1.4905 - val_accuracy: 0.6367\n",
      "Epoch 156/250\n",
      "13/13 [==============================] - 6s 441ms/step - loss: 1.2403 - accuracy: 0.6259 - val_loss: 1.5543 - val_accuracy: 0.6330\n",
      "Epoch 157/250\n",
      "13/13 [==============================] - 6s 439ms/step - loss: 1.2546 - accuracy: 0.6413 - val_loss: 1.4870 - val_accuracy: 0.6257\n",
      "Epoch 158/250\n",
      "13/13 [==============================] - 6s 425ms/step - loss: 1.1794 - accuracy: 0.6585 - val_loss: 1.4442 - val_accuracy: 0.6239\n",
      "Epoch 159/250\n",
      "13/13 [==============================] - 5s 423ms/step - loss: 1.1846 - accuracy: 0.6594 - val_loss: 1.4567 - val_accuracy: 0.6165\n",
      "Epoch 160/250\n",
      "13/13 [==============================] - 6s 428ms/step - loss: 1.2754 - accuracy: 0.6313 - val_loss: 1.5484 - val_accuracy: 0.5982\n",
      "Epoch 161/250\n",
      "13/13 [==============================] - 6s 425ms/step - loss: 1.2765 - accuracy: 0.6395 - val_loss: 1.4271 - val_accuracy: 0.6569\n",
      "Epoch 162/250\n",
      "13/13 [==============================] - 5s 408ms/step - loss: 1.1278 - accuracy: 0.6676 - val_loss: 1.3861 - val_accuracy: 0.6550\n",
      "Epoch 163/250\n",
      "13/13 [==============================] - 5s 402ms/step - loss: 1.1335 - accuracy: 0.6803 - val_loss: 1.3853 - val_accuracy: 0.6385\n",
      "Epoch 164/250\n",
      "13/13 [==============================] - 5s 407ms/step - loss: 1.1948 - accuracy: 0.6522 - val_loss: 1.4003 - val_accuracy: 0.6422\n",
      "Epoch 165/250\n",
      "13/13 [==============================] - 5s 405ms/step - loss: 1.1772 - accuracy: 0.6630 - val_loss: 1.4993 - val_accuracy: 0.6092\n",
      "Epoch 166/250\n",
      "13/13 [==============================] - 6s 433ms/step - loss: 1.1662 - accuracy: 0.6495 - val_loss: 1.4090 - val_accuracy: 0.6349\n",
      "Epoch 167/250\n",
      "13/13 [==============================] - 5s 407ms/step - loss: 1.0451 - accuracy: 0.6875 - val_loss: 1.4574 - val_accuracy: 0.6477\n",
      "Epoch 168/250\n",
      "13/13 [==============================] - 5s 413ms/step - loss: 1.0654 - accuracy: 0.6911 - val_loss: 1.3791 - val_accuracy: 0.6514\n",
      "Epoch 169/250\n",
      "13/13 [==============================] - 5s 399ms/step - loss: 1.0472 - accuracy: 0.7020 - val_loss: 1.3800 - val_accuracy: 0.6514\n",
      "Epoch 170/250\n",
      "13/13 [==============================] - 5s 400ms/step - loss: 1.1686 - accuracy: 0.6486 - val_loss: 1.3863 - val_accuracy: 0.6569\n",
      "Epoch 171/250\n",
      "13/13 [==============================] - 5s 422ms/step - loss: 1.3337 - accuracy: 0.6449 - val_loss: 1.6044 - val_accuracy: 0.6165\n",
      "Epoch 172/250\n",
      "13/13 [==============================] - 5s 382ms/step - loss: 1.1453 - accuracy: 0.6721 - val_loss: 1.4659 - val_accuracy: 0.6495\n",
      "Epoch 173/250\n",
      "13/13 [==============================] - 5s 422ms/step - loss: 0.9791 - accuracy: 0.7138 - val_loss: 1.7220 - val_accuracy: 0.6220\n",
      "Epoch 174/250\n",
      "13/13 [==============================] - 5s 414ms/step - loss: 1.2113 - accuracy: 0.6667 - val_loss: 1.4940 - val_accuracy: 0.6349\n",
      "Epoch 175/250\n",
      "13/13 [==============================] - 6s 431ms/step - loss: 1.0474 - accuracy: 0.6957 - val_loss: 1.4825 - val_accuracy: 0.6514\n",
      "Epoch 176/250\n",
      "13/13 [==============================] - 5s 417ms/step - loss: 0.8900 - accuracy: 0.7264 - val_loss: 1.3966 - val_accuracy: 0.6514\n",
      "Epoch 177/250\n",
      "13/13 [==============================] - 5s 413ms/step - loss: 0.9195 - accuracy: 0.7246 - val_loss: 1.3864 - val_accuracy: 0.6569\n",
      "Epoch 178/250\n",
      "13/13 [==============================] - 5s 394ms/step - loss: 0.8752 - accuracy: 0.7319 - val_loss: 1.3992 - val_accuracy: 0.6734\n",
      "Epoch 179/250\n",
      "13/13 [==============================] - 5s 405ms/step - loss: 0.8919 - accuracy: 0.7346 - val_loss: 1.3845 - val_accuracy: 0.6807\n",
      "Epoch 180/250\n",
      "13/13 [==============================] - 5s 384ms/step - loss: 0.9625 - accuracy: 0.7364 - val_loss: 1.3749 - val_accuracy: 0.6881\n",
      "Epoch 181/250\n",
      "13/13 [==============================] - 6s 427ms/step - loss: 0.9294 - accuracy: 0.7246 - val_loss: 1.3677 - val_accuracy: 0.6606\n",
      "Epoch 182/250\n",
      "13/13 [==============================] - 5s 400ms/step - loss: 0.7978 - accuracy: 0.7536 - val_loss: 1.3487 - val_accuracy: 0.6807\n",
      "Epoch 183/250\n",
      "13/13 [==============================] - 5s 396ms/step - loss: 0.8368 - accuracy: 0.7509 - val_loss: 1.3651 - val_accuracy: 0.6844\n",
      "Epoch 184/250\n",
      "13/13 [==============================] - 5s 395ms/step - loss: 0.7886 - accuracy: 0.7636 - val_loss: 1.3969 - val_accuracy: 0.6807\n",
      "Epoch 185/250\n",
      "13/13 [==============================] - 5s 402ms/step - loss: 0.8237 - accuracy: 0.7400 - val_loss: 1.3407 - val_accuracy: 0.6789\n",
      "Epoch 186/250\n",
      "13/13 [==============================] - 5s 403ms/step - loss: 0.8493 - accuracy: 0.7491 - val_loss: 1.3443 - val_accuracy: 0.6862\n",
      "Epoch 187/250\n",
      "13/13 [==============================] - 6s 427ms/step - loss: 0.9069 - accuracy: 0.7346 - val_loss: 1.3936 - val_accuracy: 0.6716\n",
      "Epoch 188/250\n",
      "13/13 [==============================] - 6s 423ms/step - loss: 0.7848 - accuracy: 0.7717 - val_loss: 1.2989 - val_accuracy: 0.7101\n",
      "Epoch 189/250\n",
      "13/13 [==============================] - 6s 422ms/step - loss: 0.7637 - accuracy: 0.7636 - val_loss: 1.3234 - val_accuracy: 0.6954\n",
      "Epoch 190/250\n",
      "13/13 [==============================] - 6s 465ms/step - loss: 0.7949 - accuracy: 0.7708 - val_loss: 1.6089 - val_accuracy: 0.6312\n",
      "Epoch 191/250\n",
      "13/13 [==============================] - 6s 451ms/step - loss: 0.8076 - accuracy: 0.7591 - val_loss: 1.3455 - val_accuracy: 0.6807\n",
      "Epoch 192/250\n",
      "13/13 [==============================] - 6s 433ms/step - loss: 0.7725 - accuracy: 0.7609 - val_loss: 1.4695 - val_accuracy: 0.6807\n",
      "Epoch 193/250\n",
      "13/13 [==============================] - 5s 417ms/step - loss: 0.7098 - accuracy: 0.7953 - val_loss: 1.3620 - val_accuracy: 0.6734\n",
      "Epoch 194/250\n",
      "13/13 [==============================] - 5s 413ms/step - loss: 0.7687 - accuracy: 0.7745 - val_loss: 1.3495 - val_accuracy: 0.6807\n",
      "Epoch 195/250\n",
      "13/13 [==============================] - 5s 400ms/step - loss: 0.7842 - accuracy: 0.7663 - val_loss: 1.3619 - val_accuracy: 0.6789\n",
      "Epoch 196/250\n",
      "13/13 [==============================] - 5s 412ms/step - loss: 0.7200 - accuracy: 0.7862 - val_loss: 1.4039 - val_accuracy: 0.6826\n",
      "Epoch 197/250\n",
      "13/13 [==============================] - 5s 404ms/step - loss: 0.5936 - accuracy: 0.8170 - val_loss: 1.3965 - val_accuracy: 0.6881\n",
      "Epoch 198/250\n",
      "13/13 [==============================] - 5s 408ms/step - loss: 0.6885 - accuracy: 0.7853 - val_loss: 1.4150 - val_accuracy: 0.6844\n",
      "Epoch 199/250\n",
      "13/13 [==============================] - 6s 432ms/step - loss: 0.6511 - accuracy: 0.8089 - val_loss: 1.3214 - val_accuracy: 0.6826\n",
      "Epoch 200/250\n",
      "13/13 [==============================] - 6s 449ms/step - loss: 0.5908 - accuracy: 0.8107 - val_loss: 1.3027 - val_accuracy: 0.6826\n",
      "Epoch 201/250\n",
      "13/13 [==============================] - 5s 418ms/step - loss: 0.6872 - accuracy: 0.7862 - val_loss: 1.4753 - val_accuracy: 0.6936\n",
      "Epoch 202/250\n",
      "13/13 [==============================] - 6s 428ms/step - loss: 0.6972 - accuracy: 0.7835 - val_loss: 1.3974 - val_accuracy: 0.6899\n",
      "Epoch 203/250\n",
      "13/13 [==============================] - 6s 430ms/step - loss: 0.6509 - accuracy: 0.8152 - val_loss: 1.3886 - val_accuracy: 0.6679\n",
      "Epoch 204/250\n",
      "13/13 [==============================] - 6s 425ms/step - loss: 0.6655 - accuracy: 0.8007 - val_loss: 1.3638 - val_accuracy: 0.6862\n",
      "Epoch 205/250\n",
      "13/13 [==============================] - 6s 428ms/step - loss: 0.6073 - accuracy: 0.8043 - val_loss: 1.4694 - val_accuracy: 0.6936\n",
      "Epoch 206/250\n",
      "13/13 [==============================] - 5s 407ms/step - loss: 0.6113 - accuracy: 0.8143 - val_loss: 1.3185 - val_accuracy: 0.6899\n",
      "Epoch 207/250\n",
      "13/13 [==============================] - 5s 420ms/step - loss: 0.5954 - accuracy: 0.8342 - val_loss: 1.3234 - val_accuracy: 0.6899\n",
      "Epoch 208/250\n",
      "13/13 [==============================] - 5s 395ms/step - loss: 0.5779 - accuracy: 0.8288 - val_loss: 1.3374 - val_accuracy: 0.6826\n",
      "Epoch 209/250\n",
      "13/13 [==============================] - 5s 394ms/step - loss: 0.7044 - accuracy: 0.7862 - val_loss: 1.4551 - val_accuracy: 0.6844\n",
      "Epoch 210/250\n",
      "13/13 [==============================] - 5s 394ms/step - loss: 0.6584 - accuracy: 0.7944 - val_loss: 1.3470 - val_accuracy: 0.6752\n",
      "Epoch 211/250\n",
      "13/13 [==============================] - 5s 414ms/step - loss: 0.6801 - accuracy: 0.7935 - val_loss: 1.7316 - val_accuracy: 0.6385\n",
      "Epoch 212/250\n",
      "13/13 [==============================] - 5s 424ms/step - loss: 0.7489 - accuracy: 0.7835 - val_loss: 1.3663 - val_accuracy: 0.6844\n",
      "Epoch 213/250\n",
      "13/13 [==============================] - 6s 445ms/step - loss: 0.6585 - accuracy: 0.8016 - val_loss: 1.3826 - val_accuracy: 0.6972\n",
      "Epoch 214/250\n",
      "13/13 [==============================] - 5s 415ms/step - loss: 0.6210 - accuracy: 0.8025 - val_loss: 1.3565 - val_accuracy: 0.6826\n",
      "Epoch 215/250\n",
      "13/13 [==============================] - 5s 410ms/step - loss: 0.5940 - accuracy: 0.8243 - val_loss: 1.4582 - val_accuracy: 0.6771\n",
      "Epoch 216/250\n",
      "13/13 [==============================] - 5s 409ms/step - loss: 0.5734 - accuracy: 0.8370 - val_loss: 1.3801 - val_accuracy: 0.6936\n",
      "Epoch 217/250\n",
      "13/13 [==============================] - 5s 412ms/step - loss: 0.5609 - accuracy: 0.8388 - val_loss: 1.4132 - val_accuracy: 0.6716\n",
      "Epoch 218/250\n",
      "13/13 [==============================] - 5s 411ms/step - loss: 0.5336 - accuracy: 0.8379 - val_loss: 1.5256 - val_accuracy: 0.6697\n",
      "Epoch 219/250\n",
      "13/13 [==============================] - 5s 393ms/step - loss: 0.5071 - accuracy: 0.8487 - val_loss: 1.3608 - val_accuracy: 0.6716\n",
      "Epoch 220/250\n",
      "13/13 [==============================] - 5s 397ms/step - loss: 0.5269 - accuracy: 0.8361 - val_loss: 1.5715 - val_accuracy: 0.6716\n",
      "Epoch 221/250\n",
      "13/13 [==============================] - 5s 408ms/step - loss: 0.5197 - accuracy: 0.8351 - val_loss: 1.3885 - val_accuracy: 0.6862\n",
      "Epoch 222/250\n",
      "13/13 [==============================] - 5s 420ms/step - loss: 0.5453 - accuracy: 0.8415 - val_loss: 1.4124 - val_accuracy: 0.7064\n",
      "Epoch 223/250\n",
      "13/13 [==============================] - 5s 426ms/step - loss: 0.5347 - accuracy: 0.8460 - val_loss: 1.4393 - val_accuracy: 0.7028\n",
      "Epoch 224/250\n",
      "13/13 [==============================] - 6s 436ms/step - loss: 0.5848 - accuracy: 0.8270 - val_loss: 1.4543 - val_accuracy: 0.6917\n",
      "Epoch 225/250\n",
      "13/13 [==============================] - 5s 412ms/step - loss: 0.5712 - accuracy: 0.8306 - val_loss: 1.3678 - val_accuracy: 0.6991\n",
      "Epoch 226/250\n",
      "13/13 [==============================] - 5s 412ms/step - loss: 0.5313 - accuracy: 0.8288 - val_loss: 1.3944 - val_accuracy: 0.7028\n",
      "Epoch 227/250\n",
      "13/13 [==============================] - 5s 422ms/step - loss: 0.5089 - accuracy: 0.8351 - val_loss: 1.5043 - val_accuracy: 0.6936\n",
      "Epoch 228/250\n",
      "13/13 [==============================] - 5s 419ms/step - loss: 0.5093 - accuracy: 0.8342 - val_loss: 1.4640 - val_accuracy: 0.6862\n",
      "Epoch 229/250\n",
      "13/13 [==============================] - 5s 405ms/step - loss: 0.5628 - accuracy: 0.8243 - val_loss: 1.6265 - val_accuracy: 0.6697\n",
      "Epoch 230/250\n",
      "13/13 [==============================] - 5s 425ms/step - loss: 0.5429 - accuracy: 0.8315 - val_loss: 1.3731 - val_accuracy: 0.7028\n",
      "Epoch 231/250\n",
      "13/13 [==============================] - 5s 386ms/step - loss: 0.4835 - accuracy: 0.8424 - val_loss: 1.4028 - val_accuracy: 0.7156\n",
      "Epoch 232/250\n",
      "13/13 [==============================] - 5s 399ms/step - loss: 0.5446 - accuracy: 0.8478 - val_loss: 1.4336 - val_accuracy: 0.6844\n",
      "Epoch 233/250\n",
      "13/13 [==============================] - 5s 401ms/step - loss: 0.4543 - accuracy: 0.8551 - val_loss: 1.4025 - val_accuracy: 0.7028\n",
      "Epoch 234/250\n",
      "13/13 [==============================] - 5s 406ms/step - loss: 0.4796 - accuracy: 0.8460 - val_loss: 1.3449 - val_accuracy: 0.7046\n",
      "Epoch 235/250\n",
      "13/13 [==============================] - 5s 412ms/step - loss: 0.5000 - accuracy: 0.8388 - val_loss: 1.3225 - val_accuracy: 0.7101\n",
      "Epoch 236/250\n",
      "13/13 [==============================] - 5s 409ms/step - loss: 0.4583 - accuracy: 0.8705 - val_loss: 1.4634 - val_accuracy: 0.6991\n",
      "Epoch 237/250\n",
      "13/13 [==============================] - 5s 406ms/step - loss: 0.4853 - accuracy: 0.8424 - val_loss: 1.4893 - val_accuracy: 0.7009\n",
      "Epoch 238/250\n",
      "13/13 [==============================] - 6s 425ms/step - loss: 0.4550 - accuracy: 0.8614 - val_loss: 1.3702 - val_accuracy: 0.6972\n",
      "Epoch 239/250\n",
      "13/13 [==============================] - 5s 403ms/step - loss: 0.4021 - accuracy: 0.8750 - val_loss: 1.5271 - val_accuracy: 0.6899\n",
      "Epoch 240/250\n",
      "13/13 [==============================] - 5s 416ms/step - loss: 0.4221 - accuracy: 0.8696 - val_loss: 1.4358 - val_accuracy: 0.6991\n",
      "Epoch 241/250\n",
      "13/13 [==============================] - 5s 388ms/step - loss: 0.4848 - accuracy: 0.8578 - val_loss: 1.3526 - val_accuracy: 0.7064\n",
      "Epoch 242/250\n",
      "13/13 [==============================] - 5s 390ms/step - loss: 0.4180 - accuracy: 0.8678 - val_loss: 1.4557 - val_accuracy: 0.7193\n",
      "Epoch 243/250\n",
      "13/13 [==============================] - 5s 387ms/step - loss: 0.4304 - accuracy: 0.8732 - val_loss: 1.4305 - val_accuracy: 0.7229\n",
      "Epoch 244/250\n",
      "13/13 [==============================] - 5s 408ms/step - loss: 0.3999 - accuracy: 0.8741 - val_loss: 1.4399 - val_accuracy: 0.6991\n",
      "Epoch 245/250\n",
      "13/13 [==============================] - 6s 427ms/step - loss: 0.4802 - accuracy: 0.8551 - val_loss: 1.3932 - val_accuracy: 0.6991\n",
      "Epoch 246/250\n",
      "13/13 [==============================] - 6s 435ms/step - loss: 0.4732 - accuracy: 0.8641 - val_loss: 1.5255 - val_accuracy: 0.7009\n",
      "Epoch 247/250\n",
      "13/13 [==============================] - 6s 447ms/step - loss: 0.4378 - accuracy: 0.8641 - val_loss: 1.3740 - val_accuracy: 0.7083\n",
      "Epoch 248/250\n",
      "13/13 [==============================] - 5s 413ms/step - loss: 0.4338 - accuracy: 0.8641 - val_loss: 1.4143 - val_accuracy: 0.7009\n",
      "Epoch 249/250\n",
      "13/13 [==============================] - 5s 422ms/step - loss: 0.4359 - accuracy: 0.8732 - val_loss: 1.4620 - val_accuracy: 0.7046\n",
      "Epoch 250/250\n",
      "13/13 [==============================] - 5s 409ms/step - loss: 0.3681 - accuracy: 0.8913 - val_loss: 1.6474 - val_accuracy: 0.6789\n",
      "35/35 [==============================] - 2s 44ms/step - loss: 0.0319 - accuracy: 0.9891\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 1.6474 - accuracy: 0.6789\n",
      "Train Accuracy: 98.91%\n",
      "Test Accuracy: 67.89%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Encoder les etiquettes-Creation d'uns instance de \"LabelEncoder()\"\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "labels_integer = label_encoder.fit_transform(labels)\n",
    "labels_one_hot = to_categorical(labels_integer)\n",
    "\n",
    "train, test, ytrain, ytest = train_test_split(data, labels_one_hot, test_size = 0.33, random_state = 42, shuffle = True)\n",
    "\n",
    "train = train.reshape(train.shape[0], 100, 100, 1)\n",
    "test = test.reshape(test.shape[0], 100, 100, 1)\n",
    "\n",
    "# Créez le modèle CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Ajoutez une couche de convolution avec activation ReLU\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu', input_shape = (100, 100, 1)))\n",
    "\n",
    "# Ajoutez une couche de pooling pour réduire la dimension spatiale\n",
    "model.add(MaxPooling2D((3, 3)))\n",
    "\n",
    "# Ajoutez une autre couche de convolution avec activation ReLU\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Ajoutez une autre couche de pooling\n",
    "model.add(MaxPooling2D((3, 3)))\n",
    "\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "#model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "#model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Aplatir les données avant de passer à la couche dense\n",
    "model.add(Flatten())\n",
    "\n",
    "# Ajouter une couche de \"dropout\" pour eviter l'overfitting\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "# Ajoutez une couche dense avec activation ReLU\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "\n",
    "\n",
    "# Ajoutez la couche de sortie avec activation softmax pour la classification\n",
    "model.add(Dense(128, activation = 'softmax'))\n",
    "\n",
    "# Compilez le modèle avec la fonction de perte et l'optimiseur appropriés\n",
    "model.compile(optimizer = 'adam', loss ='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Entraînez le modèle avec vos données\n",
    "model.fit(train, ytrain, epochs = 250, batch_size = 90, validation_data = (test, ytest))\n",
    "\n",
    "# Évaluer le modèle sur l'ensemble de training/test\n",
    "train_loss, train_accuracy = model.evaluate(train, ytrain)\n",
    "test_loss, test_accuracy = model.evaluate(test, ytest)\n",
    "\n",
    "print(f'Train Accuracy: {train_accuracy * 100:.2f}%')\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1f0e0fa-0447-4bd0-b7fa-2fdfccc708c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(label_encoder, \"label_encoder_signature.joblib\")\n",
    "model.save(\"Model_signature.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1b9c64-bc8a-4754-bffb-4808143c8eec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
